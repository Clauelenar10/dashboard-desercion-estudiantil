{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18807662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score, recall_score, precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49023fc",
   "metadata": {},
   "source": [
    "# CONEXIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = \"mongodb://proyectoestudiantes:suVKLoKoqjCxdeRnmZH7IICunDq54Ed33zaKcNzPBdxI2PVaohC0veT5diWHmsojaQCW6r2qohC9ACDbu5vPqQ==@proyectoestudiantes.mongo.cosmos.azure.com:10255/?ssl=true&replicaSet=globaldb&retrywrites=false&maxIdleTimeMS=120000&appName=@proyectoestudiantes@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410971cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(CONNECTION_STRING)\n",
    "db = client['Estudiantes']\n",
    "collection = db['Estudiantes_Materias']\n",
    "\n",
    "datos_raw = list(collection.find({}))\n",
    "\n",
    "registros = []\n",
    "for doc in datos_raw:\n",
    "    datos_personales = doc.get('datos_personales', {})\n",
    "    info_academica = doc.get('academico', {})\n",
    "    location = doc.get('location', {})\n",
    "    info_colegio = doc.get('colegio', {})\n",
    "    puntajes = doc.get('ICFES', {})\n",
    "    metricas = doc.get('metricas_rendimiento', {})\n",
    "    estado = doc.get('estado', {})\n",
    "    periodo_info = doc.get('periodo_info', {})\n",
    "    \n",
    "    registro = {\n",
    "        'edad': datos_personales.get('edad'),\n",
    "        'genero': datos_personales.get('genero'),\n",
    "        'estrato': datos_personales.get('estrato'),\n",
    "        'discapacidad': datos_personales.get('discapacidad'),\n",
    "        'programa': info_academica.get('programa'),\n",
    "        'programa_secundario': info_academica.get('programa_secundario'),\n",
    "        'tiene_programa_secundario': 1 if info_academica.get('programa_secundario') else 0,\n",
    "        'semestre_actual': info_academica.get('semestre_actual'),\n",
    "        'tipo_estudiante': info_academica.get('tipo_estudiante'),\n",
    "        'tipo_admision': info_academica.get('tipo_admision'),\n",
    "        'estado_academico': info_academica.get('estado_academico'),\n",
    "        'ciudad_residencia': location.get('ciudad'),\n",
    "        'depto_residencia': location.get('departamento'),\n",
    "        'pais': location.get('pais'),\n",
    "        'es_barranquilla': location.get('es_barranquilla'),\n",
    "        'es_colombia': location.get('es_colombia'),\n",
    "        'codigo_dane': location.get('codigo_dane'),\n",
    "        'tipo_colegio': info_colegio.get('tipo_colegio'),\n",
    "        'calendario_colegio': info_colegio.get('calendario_colegio'),\n",
    "        'descripcion_bachillerato': info_colegio.get('descripcion_bachillerato'),\n",
    "        'puntaje_total': puntajes.get('puntaje_total'),\n",
    "        'matematicas': puntajes.get('matematicas'),\n",
    "        'lectura_critica': puntajes.get('lectura_critica'),\n",
    "        'sociales': puntajes.get('sociales'),\n",
    "        'ciencias': puntajes.get('ciencias'),\n",
    "        'ingles': puntajes.get('ingles'),\n",
    "        'promedio': metricas.get('promedio_acumulado'),\n",
    "        'materias_cursadas': metricas.get('materias_cursadas_total'),\n",
    "        'materias_perdidas': metricas.get('materias_perdidas_total'),\n",
    "        'materias_repetidas': metricas.get('materias_repetidas'),\n",
    "        'perdidas_por_depto': metricas.get('materias_perdidas_por_departamento', {}),\n",
    "        'beca': estado.get('becado'),\n",
    "        'graduado': estado.get('graduado'),\n",
    "        'desertor': estado.get('desertor'),\n",
    "        'ultimo_periodo': periodo_info.get('ultimo_periodo')\n",
    "    }\n",
    "    registros.append(registro)\n",
    "\n",
    "df = pd.DataFrame(registros)\n",
    "df = df[df['graduado'] == False]\n",
    "\n",
    "print(f\"Datos extraidos: {df.shape[0]} estudiantes x {df.shape[1]} variables\")\n",
    "print(f\"Desertores: {df['desertor'].sum()} ({df['desertor'].sum()/len(df)*100:.2f}%)\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7541268",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe8a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Total filas: 10226\n",
      "Total columnas: 30\n",
      "\n",
      "Distribución de desertor:\n",
      "desertor\n",
      "0    9749\n",
      "1     477\n",
      "Name: count, dtype: int64\n",
      "Tasa deserción: 4.66%\n",
      "\n",
      "Procesando perdidas por departamento...\n",
      "Categorías de materias encontradas: {'Dpto. Derecho', 'Dpto. Lenguas Extranjeras', 'Dpto. Español', 'Dpto. de Economía', 'Dpto. Humanidades y Filosofía', 'Dpto. Psicología', 'Dpto. Química y Biología', 'Dpto. Salud Pública', 'Dpto. Ing. Civil y Ambiental', 'Dpto. Odontología', 'Dpto. Cs Politica y Rel Intern', 'Dpto. Historia y Cs. Sociales', 'Dpto. Ingeniería de Sistemas', 'Dpto. Ingeniería Mecánica', 'Dpto. Finanzas y Contaduría', 'Dpto. Diseño', 'Dpto. Educación', 'Dpto. Arquitectura y Urbanismo', 'Dpto. Ingeniería Industrial', 'Dpto. Matematicas y estadístic', 'Dpto. Emprendim y Management', 'Dpto. Comunicación Social', 'Dpto. Música', 'Dpto. Física', 'Dpto.Ing Eléctrica-Electrónica', 'Dpto. Enfermería', 'Dpto. Mercadeo y Neg. Internac', 'Dpto. Medicina'}\n",
      "\n",
      "Rellenando valores nulos...\n",
      "\n",
      "Valores nulos restantes: 0\n",
      "\n",
      "Datos limpios guardados: datos_limpios.csv\n",
      "Total columnas finales: 57\n",
      "Columnas: ['desertor', 'edad', 'genero', 'estrato', 'discapacidad', 'es_barranquilla', 'es_colombia', 'departamento', 'ciudad', 'pais', 'programa', 'semestre_actual', 'tipo_estudiante', 'tipo_admision', 'estado_academico', 'promedio', 'materias_cursadas', 'materias_perdidas', 'materias_repetidas', 'icfes_total', 'icfes_matematicas', 'icfes_lectura', 'icfes_ciencias', 'icfes_sociales', 'icfes_ingles', 'tipo_colegio', 'calendario_colegio', 'becado', 'graduado', 'perdidas_Dpto._Derecho', 'perdidas_Dpto._Lenguas_Extranjeras', 'perdidas_Dpto._Español', 'perdidas_Dpto._de_Economía', 'perdidas_Dpto._Humanidades_y_Filosofía', 'perdidas_Dpto._Psicología', 'perdidas_Dpto._Química_y_Biología', 'perdidas_Dpto._Salud_Pública', 'perdidas_Dpto._Ing._Civil_y_Ambiental', 'perdidas_Dpto._Odontología', 'perdidas_Dpto._Cs_Politica_y_Rel_Intern', 'perdidas_Dpto._Historia_y_Cs._Sociales', 'perdidas_Dpto._Ingeniería_de_Sistemas', 'perdidas_Dpto._Ingeniería_Mecánica', 'perdidas_Dpto._Finanzas_y_Contaduría', 'perdidas_Dpto._Diseño', 'perdidas_Dpto._Educación', 'perdidas_Dpto._Arquitectura_y_Urbanismo', 'perdidas_Dpto._Ingeniería_Industrial', 'perdidas_Dpto._Matematicas_y_estadístic', 'perdidas_Dpto._Emprendim_y_Management', 'perdidas_Dpto._Comunicación_Social', 'perdidas_Dpto._Música', 'perdidas_Dpto._Física', 'perdidas_Dpto.Ing_Eléctrica-Electrónica', 'perdidas_Dpto._Enfermería', 'perdidas_Dpto._Mercadeo_y_Neg._Internac', 'perdidas_Dpto._Medicina']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_20476\\1458097616.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_20476\\1458097616.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('Desconocido', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "perdidas_df = pd.json_normalize(df['perdidas_por_depto'])\n",
    "perdidas_df = perdidas_df.add_prefix('perdidas_')\n",
    "df = pd.concat([df.drop('perdidas_por_depto', axis=1), perdidas_df], axis=1)\n",
    "\n",
    "cols_perdidas_depto = [col for col in df.columns if col.startswith('perdidas_')]\n",
    "\n",
    "df_desertores = df[df['desertor'] == 1].copy()\n",
    "df_no_desertores = df[df['desertor'] == 0].copy()\n",
    "\n",
    "numericas = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numericas = [col for col in numericas if col not in ['desertor', 'graduado']]\n",
    "\n",
    "for col in numericas:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        if col in cols_perdidas_depto or col == 'semestre_actual':\n",
    "            # Llenar con 0: perdidas por departamento y semestre actual vacio\n",
    "            df[col] = df[col].fillna(0)\n",
    "        else:\n",
    "            mediana_desertores = df_desertores[col].median()\n",
    "            mediana_no_desertores = df_no_desertores[col].median()\n",
    "            df.loc[(df['desertor'] == 1) & (df[col].isna()), col] = mediana_desertores\n",
    "            df.loc[(df['desertor'] == 0) & (df[col].isna()), col] = mediana_no_desertores\n",
    "\n",
    "categoricas = ['genero', 'discapacidad', 'programa', 'programa_secundario', \n",
    "               'tipo_estudiante', 'tipo_admision', 'estado_academico',\n",
    "               'ciudad_residencia', 'depto_residencia', 'pais', \n",
    "               'tipo_colegio', 'calendario_colegio', 'descripcion_bachillerato',\n",
    "               'ultimo_periodo']\n",
    "\n",
    "for col in categoricas:\n",
    "    if col in df.columns and df[col].isna().sum() > 0:\n",
    "        moda_desertores = df[df['desertor'] == 1][col].mode()\n",
    "        moda_no_desertores = df[df['desertor'] == 0][col].mode()\n",
    "        valor_desertores = moda_desertores[0] if len(moda_desertores) > 0 else 'Desconocido'\n",
    "        valor_no_desertores = moda_no_desertores[0] if len(moda_no_desertores) > 0 else 'Desconocido'\n",
    "        df.loc[(df['desertor'] == 1) & (df[col].isna()), col] = valor_desertores\n",
    "        df.loc[(df['desertor'] == 0) & (df[col].isna()), col] = valor_no_desertores\n",
    "\n",
    "encoders = {}\n",
    "for col in categoricas:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        encoders[col] = le\n",
    "\n",
    "cols_object = df.select_dtypes(include=['object']).columns.tolist()\n",
    "cols_object = [col for col in cols_object if col not in ['desertor', 'graduado']]\n",
    "\n",
    "if cols_object:\n",
    "    for col in cols_object:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        encoders[col] = le\n",
    "\n",
    "print(f\"Datos procesados: {df.shape[0]} filas x {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d86b7d",
   "metadata": {},
   "source": [
    "# partición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e88f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['desertor'])\n",
    "\n",
    "X = df.drop(['desertor', 'graduado'], axis=1)\n",
    "y = df['desertor'].astype(int)\n",
    "\n",
    "# Primera división: 70% entrenamiento, 30% temporal\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Segunda división: dividir el 30% temporal en 15% validación y 15% prueba\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Escalar datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train: {X_train_scaled.shape[0]} ({X_train_scaled.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Validacion: {X_val_scaled.shape[0]} ({X_val_scaled.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test: {X_test_scaled.shape[0]} ({X_test_scaled.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"\\nDistribucion desertores:\")\n",
    "print(f\"Train: {y_train.sum()} ({y_train.sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Validacion: {y_val.sum()} ({y_val.sum()/len(y_val)*100:.1f}%)\")\n",
    "print(f\"Test: {y_test.sum()} ({y_test.sum()/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10fe54",
   "metadata": {},
   "source": [
    "# Configuración grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionarios de configuracion para grid search\n",
    "tecnicas_muestreo = {\n",
    "    'original': None,\n",
    "    'smote_30': SMOTE(sampling_strategy=0.30, random_state=42),\n",
    "    'smote_40': SMOTE(sampling_strategy=0.40, random_state=42),\n",
    "    'smote_50': SMOTE(sampling_strategy=0.50, random_state=42),\n",
    "}\n",
    "\n",
    "class_weights_base = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "cw_base_dict = {0: class_weights_base[0], 1: class_weights_base[1]}\n",
    "\n",
    "configuraciones_pesos = {\n",
    "    'balanced': cw_base_dict,\n",
    "    'high_recall_2x': {0: cw_base_dict[0], 1: cw_base_dict[1] * 2},\n",
    "    'high_recall_3x': {0: cw_base_dict[0], 1: cw_base_dict[1] * 3},\n",
    "    'moderate': {0: 1.0, 1: 10.0},\n",
    "    'none': None\n",
    "}\n",
    "\n",
    "arquitecturas = {\n",
    "    'medium_1': [256, 128, 64],\n",
    "    'medium_2': [256, 128, 64, 32],\n",
    "    'medium_3': [512, 256, 128],\n",
    "}\n",
    "\n",
    "hiperparametros = {\n",
    "    'dropout_rates': [0.2, 0.3, 0.4],\n",
    "    'learning_rates': [0.001, 0.0005],\n",
    "    'batch_sizes': [32, 64],\n",
    "    'optimizers': ['adam', 'rmsprop'],\n",
    "}\n",
    "\n",
    "regularizaciones = {\n",
    "    'none': None,\n",
    "    'l2_light': l2(0.001),\n",
    "    'l2_medium': l2(0.01),\n",
    "}\n",
    "\n",
    "thresholds = [0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f24dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar todas las combinaciones usando los diccionarios\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "configuraciones_entrenamiento = []\n",
    "\n",
    "# Recorrer cada diccionario para generar combinaciones\n",
    "for muestreo_nombre, muestreo_obj in tecnicas_muestreo.items():\n",
    "    for peso_nombre, peso_obj in configuraciones_pesos.items():\n",
    "        for arq_nombre, capas in arquitecturas.items():\n",
    "            for dropout in hiperparametros['dropout_rates']:\n",
    "                for lr in hiperparametros['learning_rates']:\n",
    "                    for bs in hiperparametros['batch_sizes']:\n",
    "                        for opt in hiperparametros['optimizers']:\n",
    "                            for reg_nombre, reg_obj in regularizaciones.items():\n",
    "                                config = {\n",
    "                                    'muestreo_nombre': muestreo_nombre,\n",
    "                                    'muestreo': muestreo_obj,\n",
    "                                    'peso_nombre': peso_nombre,\n",
    "                                    'pesos': peso_obj,\n",
    "                                    'arquitectura_nombre': arq_nombre,\n",
    "                                    'capas': capas,\n",
    "                                    'dropout': dropout,\n",
    "                                    'learning_rate': lr,\n",
    "                                    'batch_size': bs,\n",
    "                                    'optimizer': opt,\n",
    "                                    'regularizacion_nombre': reg_nombre,\n",
    "                                    'regularizacion': reg_obj,\n",
    "                                }\n",
    "                                configuraciones_entrenamiento.append(config)\n",
    "\n",
    "\n",
    "# Limitar a 500 configuraciones aleatorias si hay muchas\n",
    "if len(configuraciones_entrenamiento) > 500:\n",
    "    random.shuffle(configuraciones_entrenamiento)\n",
    "    configuraciones_entrenamiento = configuraciones_entrenamiento[:500]\n",
    "\n",
    "print(f\"Configuraciones generadas: {len(configuraciones_entrenamiento)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar todos los modelos\n",
    "\n",
    "\n",
    "resultados_busqueda = []\n",
    "modelos_entrenados = {}\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, verbose=0)\n",
    "\n",
    "print(f\"Entrenando {len(configuraciones_entrenamiento)} modelos...\")\n",
    "tiempo_inicio_global = time.time()\n",
    "\n",
    "# Barra de progreso\n",
    "pbar = tqdm(enumerate(configuraciones_entrenamiento, 1), total=len(configuraciones_entrenamiento), \n",
    "            desc=\"Entrenando modelos\", unit=\"modelo\")\n",
    "\n",
    "for idx, config in pbar:\n",
    "    try:\n",
    "        # Aplicar tecnica de muestreo\n",
    "        if config['muestreo'] is not None:\n",
    "            X_train_prep, y_train_prep = config['muestreo'].fit_resample(X_train_scaled, y_train)\n",
    "        else:\n",
    "            X_train_prep = X_train_scaled\n",
    "            y_train_prep = y_train\n",
    "        \n",
    "        # Construir modelo\n",
    "        modelo = Sequential()\n",
    "        modelo.add(Dense(config['capas'][0], activation='relu', input_dim=X_train_prep.shape[1], \n",
    "                        kernel_regularizer=config['regularizacion']))\n",
    "        modelo.add(Dropout(config['dropout']))\n",
    "        \n",
    "        for units in config['capas'][1:]:\n",
    "            modelo.add(Dense(units, activation='relu', kernel_regularizer=config['regularizacion']))\n",
    "            modelo.add(Dropout(config['dropout']))\n",
    "        \n",
    "        modelo.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        # Configurar optimizador\n",
    "        if config['optimizer'] == 'adam':\n",
    "            opt = Adam(learning_rate=config['learning_rate'])\n",
    "        else:\n",
    "            opt = RMSprop(learning_rate=config['learning_rate'])\n",
    "        \n",
    "        modelo.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Entrenar\n",
    "        inicio = time.time()\n",
    "        history = modelo.fit(\n",
    "            X_train_prep, y_train_prep, epochs=100, batch_size=config['batch_size'],\n",
    "            validation_data=(X_val_scaled, y_val), class_weight=config['pesos'], \n",
    "            callbacks=[early_stop, reduce_lr], verbose=0\n",
    "        )\n",
    "        tiempo_entrenamiento = time.time() - inicio\n",
    "        \n",
    "        # Predecir en validación\n",
    "        y_pred_proba = modelo.predict(X_val_scaled, verbose=0).flatten()\n",
    "        \n",
    "        # Guardar modelo\n",
    "        modelo_id = f\"modelo_{idx}\"\n",
    "        modelos_entrenados[modelo_id] = {\n",
    "            'modelo': modelo,\n",
    "            'config': config,\n",
    "            'y_pred_proba': y_pred_proba,\n",
    "            'history': history\n",
    "        }\n",
    "        \n",
    "        # Evaluar con diferentes thresholds\n",
    "        for thresh in thresholds:\n",
    "            y_pred = (y_pred_proba >= thresh).astype(int)\n",
    "            \n",
    "            recall = recall_score(y_val, y_pred)\n",
    "            precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_val, y_pred)\n",
    "            auc = roc_auc_score(y_val, y_pred_proba)\n",
    "            \n",
    "            cm = confusion_matrix(y_val, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            \n",
    "            score_custom = 0.6 * recall + 0.3 * auc + 0.1 * precision\n",
    "            \n",
    "            resultado = {\n",
    "                'modelo_id': modelo_id, 'config_idx': idx,\n",
    "                'muestreo': config['muestreo_nombre'], 'pesos': config['peso_nombre'],\n",
    "                'arquitectura': config['arquitectura_nombre'], 'capas': str(config['capas']),\n",
    "                'dropout': config['dropout'], 'learning_rate': config['learning_rate'],\n",
    "                'batch_size': config['batch_size'], 'optimizer': config['optimizer'],\n",
    "                'regularizacion': config['regularizacion_nombre'], 'threshold': thresh,\n",
    "                'recall': recall, 'precision': precision, 'f1': f1, 'auc': auc,\n",
    "                'score_custom': score_custom, 'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,\n",
    "                'epochs': len(history.history['loss']), 'tiempo': tiempo_entrenamiento\n",
    "            }\n",
    "            resultados_busqueda.append(resultado)\n",
    "        \n",
    "        # Actualizar barra de progreso\n",
    "        tiempo_transcurrido = time.time() - tiempo_inicio_global\n",
    "        tiempo_restante = (tiempo_transcurrido / idx) * (len(configuraciones_entrenamiento) - idx)\n",
    "        pbar.set_postfix({\n",
    "            'Tiempo': f'{tiempo_transcurrido/60:.1f}min',\n",
    "            'Restante': f'~{tiempo_restante/60:.1f}min',\n",
    "            'Modelos': len(modelos_entrenados)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        pbar.write(f\"Error en modelo {idx}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "tiempo_total = time.time() - tiempo_inicio_global\n",
    "print(f\"\\nEntrenamiento completado en {tiempo_total/60:.2f} minutos\")\n",
    "print(f\"Modelos: {len(modelos_entrenados)} | Evaluaciones: {len(resultados_busqueda)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687da48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar resultados - Solo modelos con recall > 75%\n",
    "df_resultados = pd.DataFrame(resultados_busqueda)\n",
    "\n",
    "# Filtrar solo modelos con recall mayor a 75%\n",
    "df_high_recall = df_resultados[df_resultados['recall'] > 0.75].copy()\n",
    "\n",
    "print(\"ANALISIS DE RESULTADOS - MODELOS CON RECALL > 75%\")\n",
    "print(f\"\\nTotal de evaluaciones: {len(df_resultados)}\")\n",
    "print(f\"Evaluaciones con recall > 75%: {len(df_high_recall)} ({len(df_high_recall)/len(df_resultados)*100:.1f}%)\")\n",
    "\n",
    "if len(df_high_recall) > 0:\n",
    "    print(f\"\\nEstadisticas de modelos con recall > 75%:\")\n",
    "    print(f\"Recall - Media: {df_high_recall['recall'].mean():.3f} | Max: {df_high_recall['recall'].max():.3f}\")\n",
    "    print(f\"Precision - Media: {df_high_recall['precision'].mean():.3f} | Max: {df_high_recall['precision'].max():.3f}\")\n",
    "    print(f\"F1 - Media: {df_high_recall['f1'].mean():.3f} | Max: {df_high_recall['f1'].max():.3f}\")\n",
    "    print(f\"AUC - Media: {df_high_recall['auc'].mean():.3f} | Max: {df_high_recall['auc'].max():.3f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(f\"TOP 20 MODELOS CON RECALL > 75% (ordenados por score personalizado)\")\n",
    "    print(f\"{'='*120}\")\n",
    "    top_high_recall = df_high_recall.nlargest(10, 'score_custom')\n",
    "    print(top_high_recall[['modelo_id', 'muestreo', 'pesos', 'arquitectura', 'dropout', 'learning_rate', \n",
    "                            'batch_size', 'optimizer', 'threshold', 'recall', 'precision', 'f1', 'auc', \n",
    "                            'score_custom', 'tp', 'fp', 'fn']].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(f\"MEJOR BALANCE (TOP 10 por Precision entre modelos con Recall > 75%)\")\n",
    "    print(f\"{'='*120}\")\n",
    "    top_precision = df_high_recall.nlargest(10, 'precision')\n",
    "    print(top_precision[['modelo_id', 'muestreo', 'pesos', 'arquitectura', 'threshold', \n",
    "                         'recall', 'precision', 'f1', 'auc', 'tp', 'fp', 'fn']].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(f\"MAXIMA DETECCION (TOP 10 por Recall)\")\n",
    "    print(f\"{'='*120}\")\n",
    "    top_recall = df_high_recall.nlargest(10, 'recall')\n",
    "    print(top_recall[['modelo_id', 'muestreo', 'pesos', 'arquitectura', 'threshold', \n",
    "                      'recall', 'precision', 'f1', 'auc', 'tp', 'fp', 'fn']].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(f\"MEJOR AUC (TOP 10)\")\n",
    "    print(f\"{'='*120}\")\n",
    "    top_auc = df_high_recall.nlargest(10, 'auc')\n",
    "    print(top_auc[['modelo_id', 'muestreo', 'pesos', 'arquitectura', 'threshold', \n",
    "                   'recall', 'precision', 'f1', 'auc', 'tp', 'fp', 'fn']].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo se encontraron modelos con recall mayor a 75%\")\n",
    "    print(\"\\nMejores modelos disponibles:\")\n",
    "    print(df_resultados.nlargest(10, 'recall')[['modelo_id', 'recall', 'precision', 'f1', 'auc']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar mejor modelo\n",
    "mejor_config = df_resultados.nlargest(1, 'score_custom').iloc[0]\n",
    "mejor_modelo_id = mejor_config['modelo_id']\n",
    "mejor_modelo_info = modelos_entrenados[mejor_modelo_id]\n",
    "\n",
    "print(\"MEJOR MODELO\")\n",
    "print(f\"\\nModelo: {mejor_modelo_id}\")\n",
    "print(f\"Muestreo: {mejor_config['muestreo']} | Pesos: {mejor_config['pesos']}\")\n",
    "print(f\"Arquitectura: {mejor_config['arquitectura']} {mejor_config['capas']}\")\n",
    "print(f\"Threshold: {mejor_config['threshold']} | Dropout: {mejor_config['dropout']} | LR: {mejor_config['learning_rate']}\")\n",
    "print(f\"\\nMetricas:\")\n",
    "print(f\"Recall: {mejor_config['recall']:.3f} | Precision: {mejor_config['precision']:.3f}\")\n",
    "print(f\"F1-Score: {mejor_config['f1']:.3f} | AUC: {mejor_config['auc']:.3f}\")\n",
    "print(f\"\\nMatriz de confusion:\")\n",
    "print(f\"TP: {mejor_config['tp']} | FP: {mejor_config['fp']} | TN: {mejor_config['tn']} | FN: {mejor_config['fn']}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "y_pred_mejor = (mejor_modelo_info['y_pred_proba'] >= mejor_config['threshold']).astype(int)\n",
    "cm = confusion_matrix(y_val, y_pred_mejor)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])\n",
    "axes[0, 0].set_title(f'Matriz de Confusion\\nRecall: {mejor_config[\"recall\"]:.3f} | Precision: {mejor_config[\"precision\"]:.3f}')\n",
    "axes[0, 0].set_ylabel('Verdadero')\n",
    "axes[0, 0].set_xlabel('Predicho')\n",
    "axes[0, 0].set_xticklabels(['No Desertor', 'Desertor'])\n",
    "axes[0, 0].set_yticklabels(['No Desertor', 'Desertor'])\n",
    "\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_val, mejor_modelo_info['y_pred_proba'])\n",
    "axes[0, 1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {mejor_config[\"auc\"]:.3f})')\n",
    "axes[0, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[0, 1].set_xlim([0.0, 1.0])\n",
    "axes[0, 1].set_ylim([0.0, 1.05])\n",
    "axes[0, 1].set_xlabel('Tasa de Falsos Positivos')\n",
    "axes[0, 1].set_ylabel('Tasa de Verdaderos Positivos (Recall)')\n",
    "axes[0, 1].set_title('Curva ROC')\n",
    "axes[0, 1].legend(loc=\"lower right\")\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].hist(mejor_modelo_info['y_pred_proba'][y_val == 0], bins=50, alpha=0.5, label='No Desertor', color='blue')\n",
    "axes[1, 0].hist(mejor_modelo_info['y_pred_proba'][y_val == 1], bins=50, alpha=0.5, label='Desertor', color='red')\n",
    "axes[1, 0].axvline(mejor_config['threshold'], color='green', linestyle='--', linewidth=2, label=f'Threshold={mejor_config[\"threshold\"]:.2f}')\n",
    "axes[1, 0].set_xlabel('Probabilidad predicha')\n",
    "axes[1, 0].set_ylabel('Frecuencia')\n",
    "axes[1, 0].set_title('Distribucion de Probabilidades Predichas')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "thresholds_test = [0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "\n",
    "for thresh in thresholds_test:\n",
    "    y_pred_temp = (mejor_modelo_info['y_pred_proba'] >= thresh).astype(int)\n",
    "    recalls.append(recall_score(y_val, y_pred_temp))\n",
    "    precisions.append(precision_score(y_val, y_pred_temp, zero_division=0))\n",
    "    f1s.append(f1_score(y_val, y_pred_temp))\n",
    "\n",
    "axes[1, 1].plot(thresholds_test, recalls, 'o-', label='Recall', linewidth=2, markersize=8)\n",
    "axes[1, 1].plot(thresholds_test, precisions, 's-', label='Precision', linewidth=2, markersize=8)\n",
    "axes[1, 1].plot(thresholds_test, f1s, '^-', label='F1-Score', linewidth=2, markersize=8)\n",
    "axes[1, 1].axvline(mejor_config['threshold'], color='red', linestyle='--', alpha=0.5, label=f'Seleccionado={mejor_config[\"threshold\"]:.2f}')\n",
    "axes[1, 1].set_xlabel('Threshold')\n",
    "axes[1, 1].set_ylabel('Metrica')\n",
    "axes[1, 1].set_title('Metricas vs Threshold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar predicciones\n",
    "mejores_probabilidades = mejor_modelo_info['y_pred_proba']\n",
    "\n",
    "df_predicciones = pd.DataFrame({\n",
    "    'indice_original': X_val.index,\n",
    "    'probabilidad_desercion': mejores_probabilidades,\n",
    "    'desertor_real': y_val.values,\n",
    "    'prediccion': y_pred_mejor\n",
    "})\n",
    "\n",
    "df_predicciones = df_predicciones.sort_values('probabilidad_desercion', ascending=False)\n",
    "\n",
    "print(\"TOP 20 ESTUDIANTES CON MAYOR RIESGO DE DESERCION\")\n",
    "print(df_predicciones.head(20).to_string(index=False))\n",
    "\n",
    "estudiantes_en_riesgo = df_predicciones[df_predicciones['probabilidad_desercion'] >= mejor_config['threshold']]\n",
    "print(f\"\\nRESUMEN\")\n",
    "print(f\"Estudiantes evaluados: {len(df_predicciones)}\")\n",
    "print(f\"Identificados en riesgo: {len(estudiantes_en_riesgo)} ({len(estudiantes_en_riesgo)/len(df_predicciones)*100:.2f}%)\")\n",
    "print(f\"Verdaderos positivos: {estudiantes_en_riesgo['desertor_real'].sum()}\")\n",
    "print(f\"Falsos positivos: {(estudiantes_en_riesgo['desertor_real'] == 0).sum()}\")\n",
    "\n",
    "print(f\"\\nDISTRIBUCION DE PROBABILIDADES\")\n",
    "rangos = [\n",
    "    (0.0, 0.2, 'Riesgo muy bajo'),\n",
    "    (0.2, 0.4, 'Riesgo bajo'),\n",
    "    (0.4, 0.6, 'Riesgo moderado'),\n",
    "    (0.6, 0.8, 'Riesgo alto'),\n",
    "    (0.8, 1.0, 'Riesgo muy alto')\n",
    "]\n",
    "\n",
    "for inicio, fin, etiqueta in rangos:\n",
    "    count = ((df_predicciones['probabilidad_desercion'] >= inicio) & \n",
    "             (df_predicciones['probabilidad_desercion'] < fin)).sum()\n",
    "    pct = count / len(df_predicciones) * 100\n",
    "    print(f\"{etiqueta} [{inicio:.1f}-{fin:.1f}): {count} estudiantes ({pct:.2f}%)\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUACIÓN DEL MODELO CON MEJORAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# PASO 1: Cargar modelo y datos de test\n",
    "print(\"\\n1. Cargando modelo y datos...\")\n",
    "model = tf.keras.models.load_model('modelo_desercion.h5', compile=False)\n",
    "\n",
    "X_test = np.load('X_test.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "print(f\"Modelo cargado\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# PASO 2: Hacer predicciones con THRESHOLD AJUSTADO\n",
    "print(\"\\n2. Haciendo predicciones...\")\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# MEJORA 1: Threshold más bajo para detectar más desertores\n",
    "THRESHOLD = 0.3  # Bajado de 0.5 a 0.3\n",
    "y_pred = (y_pred_proba > THRESHOLD).astype(int).flatten()\n",
    "\n",
    "print(f\"Predicciones completadas con threshold = {THRESHOLD}\")\n",
    "\n",
    "# PASO 3: Métricas generales\n",
    "print(\"\\n3. MÉTRICAS DE EVALUACIÓN:\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Desertor', 'Desertor']))\n",
    "\n",
    "# ROC-AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nROC-AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# PASO 4: Matriz de confusión\n",
    "print(\"\\n4. Matriz de Confusión:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Calcular métricas específicas\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nDesertores detectados: {tp} de {tp+fn} ({tp/(tp+fn)*100:.2f}%)\")\n",
    "print(f\"Falsos positivos: {fp}\")\n",
    "print(f\"Verdaderos negativos: {tn}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Desertor', 'Desertor'],\n",
    "            yticklabels=['No Desertor', 'Desertor'])\n",
    "plt.title(f'Matriz de Confusión (threshold={THRESHOLD})')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicción')\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusion_mejorada.png', dpi=300)\n",
    "print(\"\\nMatriz guardada: matriz_confusion_mejorada.png\")\n",
    "\n",
    "# PASO 5: Curva ROC\n",
    "print(\"\\n5. Curva ROC:\")\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {auc_score:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "plt.scatter([fp/(fp+tn)], [tp/(tp+fn)], color='red', s=100, zorder=5, \n",
    "            label=f'Threshold={THRESHOLD}')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('Curva ROC - Modelo Mejorado')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('curva_roc_mejorada.png', dpi=300)\n",
    "print(\"Curva ROC guardada: curva_roc_mejorada.png\")\n",
    "\n",
    "# PASO 6: Análisis de threshold óptimo\n",
    "print(\"\\n6. ANÁLISIS DE DIFERENTES THRESHOLDS:\")\n",
    "print(\"-\" * 70)\n",
    "for thresh in [0.2, 0.3, 0.4, 0.5]:\n",
    "    y_pred_temp = (y_pred_proba > thresh).astype(int).flatten()\n",
    "    cm_temp = confusion_matrix(y_test, y_pred_temp)\n",
    "    tn_t, fp_t, fn_t, tp_t = cm_temp.ravel()\n",
    "    \n",
    "    recall = tp_t / (tp_t + fn_t)\n",
    "    precision = tp_t / (tp_t + fp_t) if (tp_t + fp_t) > 0 else 0\n",
    "    \n",
    "    print(f\"Threshold {thresh}: Recall={recall:.3f} | Precision={precision:.3f} | Detectados={tp_t}/{tp_t+fn_t}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"¡EVALUACIÓN COMPLETADA!\")\n",
    "print(\"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Basico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
